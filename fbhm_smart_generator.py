# -*- coding: utf-8 -*-
"""fbhm_smart_generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_eK7pYDDxbzxwtvUHNh5x9Gkn5M557W6
"""

# pip install flashtext

import random 
import itertools
import pandas as pd

from flashtext import KeywordProcessor
from itertools import chain, combinations
from  more_itertools import unique_everseen
from torch.utils.data.sampler import Sampler

def keyword_idx(texts, keyword, mode='flashtext'):
  idx = texts.index
  if mode is 'flashtext':
    kp = KeywordProcessor()
    kp.add_keywords_from_list(keyword)
    keyword_found = [kp.extract_keywords(text) for text in texts]
    keyword_found = [True if keyword else False for keyword in keyword_found]
  elif mode is 'regex':
    return None
  
  return set(idx[keyword_found].tolist())

def common(sets, shuffle=True):
  if sets:
    common_elements = list(set.intersection(*sets))
    if not common_elements:
      return []
    random.shuffle(common_elements)
    return common_elements
  return []

def uniq(idx_list):
  flatten = itertools.chain.from_iterable
  idx = flatten(idx_list)
  return list(unique_everseen(idx))

def all_combinations(ss):
    return chain(*map(lambda x: combinations(ss, x), reversed(range(1, len(ss)+1))))

def set_redistribution(sets, shuffle=True):
  n = len(sets)
  set_combos = all_combinations(sets)
  idx = []
  for i, s in enumerate(set_combos): # 2^m
    common_idx = common(sets=s, shuffle=shuffle)
    # print(f'{i}: {len(common_idx)}')
    if common_idx:
      idx.append(common_idx)
  return uniq(idx)

f = './train.jsonl'
df = pd.read_json(f, lines=True)
texts = df['text']

keywords = {
    'skin_color' : { 
        'b' : ['black', 'blacks', "blackman's", 'blacker'],
        'w' : ['white', 'whites', 'whitetrash'],
    },
    'race' : {
        'r' : ['racist', 'racists'],
        'j' : ['jew', 'jews', 'jewish'],
    },
    'people ' : {
        'o' : ['obama', 'obamacare'],
        'h' : ['hitler', 'mchitler'],
        't' : ['trump', 'trumps', 'trumpanzee'],
    },
    'curse' : { 
        'f' : ['fuck'],
        'b' : ['bitch', 'bitches'],
        'd' : ['dick', 'dicks'],
        's' : ['shit', 'shithole', 'shits', 'shitter'],
    },
    'animals' : {
        'd' : ['dogs', 'dog', 'dogshit'],
        'c' : ['cats', 'cat'],
        'g' : ['goat', 'goats', 'goatfucker', 'goatfuckers', 'goatshit', 'goatshaggers'],
        'ca' : ['camel'],
    },
    'religion' : {
        'i' : ['islam', 'islamic', 'islamaphobe', 'islamomopolitan', 'islamist', 
               'islamophobia', 'islamophobic'],
        'm' : ['muslim', 'muslims'],
        'c' : ['christian', 'christians'],
        'g' : ['god', 'gods'],
    },
    'gender' : { 
        'w' : ['women', 'womens'],
        'ga' : ['gay', 'gays'],
        't' : ['trans', 'transgender', 'transgenderism', 'transphobic', 'transwoman'],
        'tr' : ['tranny', 'trannies'],
        'h' : ['homophobe', 'homosexuals', 'homosexuality', 'homosexuals', 'homophobia', 'homophobic'],
        'b' : ['beat', 'beating'],
        'c' : ['children', 'child'],
        'e' : ['eat', 'eating', 'eats'],
    },
    'authority' : {
        'g' : ['government'],
        'i' : ['isis'],
        'c' : ['congress'],
        'h' : ['homeland'],
        'sc' : ['school', 'schools'],
    },
    'party' : {
        'd' : ['democrat', 'democratic', 'democrats'],
        'r' : ['republicans', 'republican'],
    },
    'country' : {
        'a' : ['america', 'american', 'americas', 'americans'],
        'i' : ['india', 'indians'],
        'r' : ['russia', 'russians'],
        'c' : ['china', 'chinese', 'ching'],
        'g' : ['german', 'germany', 'germans'],
        'm' : ['mexicans', 'mexico', 'mexican'],
        'af' : ['africa', 'african', 'africans'],
        'is' : ['israel', 'israelite'],
        'p' : ['palestine'],
        'co' : ['country'],
    },
    'money' : {
        'm' : ['millions', 'million'],
        'b' : ['billions', 'billion'],
        'h' : ['hundreds', 'hundred'],
    },
    'acts' : {
        's' : ['sex', 'sexual', 'sexually'],
        'r' : ['rape', 'rapist', 'raped', 'raper', 'rapists', 'raping'],
        'c' : ['crime', 'criminal', 'criminals'],
        't' : ['terrorist', 'terrorism', 'terrorists'],
        'i' : ['illegal', 'illegals', 'illegally'],
        'l' : ['legal', 'legally'],
        'k' : ['kill', 'killed', 'killing', 'kills', 'killer', 'killers'],
        'sh' : ['shoot', 'shoots', 'shooter', 'shooters', 'shooting']
    },
    'food' : {
        'f' : ['food'],
        'p' : ['potato', 'potatoes'],
    },
    'body_part' : {
        'h' : ['hand', 'hands'],
        'l' : ['leg', 'legs'],
    },
    'emotion' : {
        'h' : ['hate', 'hater', 'hates'],
        'l' : ['love', 'lover', 'loves'],
    },
    'chronology' : {
        't' : ['time', 'times'],
        'm' : ['month', 'months'],
        'y' : ['year', 'years'],
        'd' : ['day', 'days'],
        'b' : ['birthday'],
        'to' : ['today', 'tomorrow'],
        's' : ['second', 'seconds'],
    },
    'color' : {
        'r' : ['red'],
        'b' : ['blue'],
        'g' : ['green'],
    },
    'misc' : {
        'p' : ['problem', 'problems'],
        'm' : ['meme', 'memes'],
        'f' : ['free', 'freed', 'freedom']
    }
}

def smart_iter(texts, keywords):
  texts_unseen = texts
  ult_idx = []
  for k, v in keywords.items():
    idx_sets = [keyword_idx(texts_unseen, keywords[k][v_]) for v_ in v.keys()]
    idx = set_redistribution(idx_sets)
    texts_unseen = texts_unseen.drop(index=idx)
    # print(f'{k}: {len(idx)}')
    ult_idx = ult_idx + idx
    # print(f'unique idx processed: {len(ult_idx)}')
    # print(f'unseen text: {len(texts_unseen)}')
  
  remaining_idx = texts_unseen.index.values.tolist()
  random.shuffle(remaining_idx)
  ult_idx = ult_idx + remaining_idx
  return ult_idx


idx1 = smart_iter(texts, keywords)
print(f'idx list len: {len(idx1)}')

class SmartSampler(Sampler):
    def __init__(self, idx_list):
        self.idx = idx_list

    def __iter__(self):
        return iter(self.idx)

    def __len__(self):
        return len(self.idx)

sampler = SmartSampler(idx1)